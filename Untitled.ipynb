{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5af2248-1d7a-41c4-8248-6b8c1f827e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/jc5933/jcproject/miniconda3/envs/pytorch/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from xunet import XUNet\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm import tqdm\n",
    "from einops import rearrange\n",
    "import time\n",
    "\n",
    "from SRNdataset import dataset, MultiEpochsDataLoader\n",
    "from tensorboardX import SummaryWriter\n",
    "import os\n",
    "import glob\n",
    "from PIL import Image\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df96d704-b246-4761-b156-974800339928",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--model',type=str, default=\"./trained_model.pt\")\n",
    "parser.add_argument('--target',type=str, default=\"./data/SRN/cars_train/a4d535e1b1d3c153ff23af07d9064736\")\n",
    "args = parser.parse_args('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89470e9f-2a1f-432d-ad32-a0070f870410",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgsize = 64\n",
    "\n",
    "data_imgs = []\n",
    "data_Rs = []\n",
    "data_Ts = []\n",
    "\n",
    "for img_filename in sorted(glob.glob(args.target + \"/rgb/*.png\")):\n",
    "    img = Image.open(img_filename)\n",
    "    img = img.resize((imgsize, imgsize))\n",
    "    img = np.array(img) / 255 * 2 - 1\n",
    "\n",
    "    img = img.transpose(2,0,1)[:3].astype(np.float32)\n",
    "    data_imgs.append(img)\n",
    "    \n",
    "    pose_filename = os.path.join(args.target, 'pose', os.path.basename(img_filename)[:-4]+\".txt\")\n",
    "    pose = np.array(open(pose_filename).read().strip().split()).astype(float).reshape((4,4))\n",
    "    \n",
    "    data_Rs.append(pose[:3, :3])\n",
    "    data_Ts.append(pose[:3, 3])\n",
    "    \n",
    "\n",
    "data_K = np.array(open(os.path.join(args.target, 'intrinsics', os.path.basename(img_filename)[:-4]+\".txt\")).read().strip().split()).astype(float).reshape((3,3))\n",
    "data_K = torch.tensor(data_K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d5d582b-6ae0-4c9c-8a61-73e0679a067a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = XUNet(H=imgsize, W=imgsize, ch=128)\n",
    "model = torch.nn.DataParallel(model)\n",
    "model.to('cuda')\n",
    "\n",
    "ckpt = torch.load(args.model)\n",
    "model.load_state_dict(ckpt['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a27d319-e303-41aa-90f3-e0d152d60e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logsnr_schedule_cosine(t, *, logsnr_min=-20., logsnr_max=20.):\n",
    "    b = np.arctan(np.exp(-.5 * logsnr_max))\n",
    "    a = np.arctan(np.exp(-.5 * logsnr_min)) - b\n",
    "    \n",
    "    return -2. * torch.log(torch.tan(a * t + b))\n",
    "\n",
    "def xt2batch(x, logsnr, z, R, T, K):\n",
    "    b = x.shape[0]\n",
    "    \n",
    "\n",
    "    return {\n",
    "        'x': x.cuda(),\n",
    "        'z': z.cuda(),\n",
    "        'logsnr': torch.stack([logsnr_schedule_cosine(torch.zeros_like(logsnr)), logsnr], dim=1).cuda(),\n",
    "        'R': R.cuda(),\n",
    "        't': T.cuda(),\n",
    "        'K':K[None].repeat(b,1,1).cuda(),\n",
    "    }\n",
    "\n",
    "@torch.no_grad()\n",
    "def p_mean_variance(model, x, z, R, T, K, logsnr, logsnr_next, w):\n",
    "    \n",
    "    \n",
    "    w = w[:, None, None, None]\n",
    "    b = w.shape[0]\n",
    "    \n",
    "    c = - torch.special.expm1(logsnr - logsnr_next)\n",
    "    \n",
    "\n",
    "    squared_alpha, squared_alpha_next = logsnr.sigmoid(), logsnr_next.sigmoid()\n",
    "    squared_sigma, squared_sigma_next = (-logsnr).sigmoid(), (-logsnr_next).sigmoid()\n",
    "    \n",
    "    alpha, sigma, alpha_next = map(lambda x: x.sqrt(), (squared_alpha, squared_sigma, squared_alpha_next))\n",
    "    \n",
    "    # batch = xt2batch(x, logsnr.repeat(b), z, R)\n",
    "    batch = xt2batch(x, logsnr.repeat(b), z, R, T, K)\n",
    "    \n",
    "    \n",
    "    pred_noise = model(batch, cond_mask= torch.tensor([True]*b)).detach().cpu()\n",
    "    batch['x'] = torch.randn_like(x).cuda()\n",
    "    pred_noise_unconditioned = model(batch, cond_mask= torch.tensor([False]*b)).detach().cpu()\n",
    "    \n",
    "    pred_noise_final = (1+w) * pred_noise - w * pred_noise_unconditioned\n",
    "    \n",
    "    z = z.detach().cpu()\n",
    "    \n",
    "    z_start = (z - sigma * pred_noise_final) / alpha\n",
    "    z_start.clamp_(-1., 1.)\n",
    "    \n",
    "    model_mean = alpha_next * (z * (1 - c) / alpha + c * z_start)\n",
    "    \n",
    "    posterior_variance = squared_sigma_next * c\n",
    "    \n",
    "    return model_mean, posterior_variance\n",
    "\n",
    "@torch.no_grad()\n",
    "def p_sample(model, z, x, R, T, K, logsnr, logsnr_next, w):\n",
    "    \n",
    "    \n",
    "    model_mean, model_variance = p_mean_variance(model, \n",
    "                                                 x=x, \n",
    "                                                 z=z, \n",
    "                                                 R=R, \n",
    "                                                 T=T, K=K, logsnr=logsnr, logsnr_next=logsnr_next, w=w)\n",
    "    \n",
    "    if logsnr_next==0:\n",
    "        return model_mean\n",
    "    \n",
    "    return model_mean + model_variance.sqrt() * torch.randn_like(x).cpu()\n",
    "\n",
    "@torch.no_grad()\n",
    "def sample(model, record, target_R, target_T, K, w, timesteps=256):\n",
    "    b = w.shape[0]\n",
    "    img = torch.randn_like(torch.tensor(record[0][0]))\n",
    "    \n",
    "    logsnrs = logsnr_schedule_cosine(torch.linspace(1., 0., timesteps+1)[:-1])\n",
    "    logsnr_nexts = logsnr_schedule_cosine(torch.linspace(1., 0., timesteps+1)[1:])\n",
    "    \n",
    "    for logsnr, logsnr_next in tqdm(zip(logsnrs, logsnr_nexts), total=len(logsnrs), desc='diffusion loop', position=1, leave=False): # [1, ..., 0] = size is 257\n",
    "        condition_img, condition_R, condition_T = random.choice(record)\n",
    "        condition_img = torch.tensor(condition_img)\n",
    "        condition_R = torch.tensor(condition_R)\n",
    "        condition_T = torch.tensor(condition_T)\n",
    "        \n",
    "        R = torch.stack([condition_R, target_R], 0)[None].repeat(b, 1, 1, 1)\n",
    "        T = torch.stack([condition_T, target_T], 0)[None].repeat(b, 1, 1)\n",
    "        condition_img = condition_img\n",
    "        img = p_sample(model,\n",
    "                       z=img,\n",
    "                       x=condition_img, \n",
    "                       R=R,\n",
    "                       T=T,\n",
    "                       K=K,\n",
    "                       logsnr=logsnr, logsnr_next=logsnr_next,\n",
    "                       w=w)\n",
    "        \n",
    "        break\n",
    "        \n",
    "    return img.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2bd1b8db-8aef-4e43-af51-67ce69e0ec9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "view loop:   0%|                                                                             | 0/249 [00:00<?, ?it/s]\n",
      "diffusion loop:   0%|                                                                        | 0/256 [00:00<?, ?it/s]\u001b[A\n",
      "view loop:   0%|▎                                                                    | 1/249 [00:02<09:14,  2.24s/it]\u001b[A\n",
      "diffusion loop:   0%|                                                                        | 0/256 [00:00<?, ?it/s]\u001b[A\n",
      "view loop:   1%|▌                                                                    | 2/249 [00:04<08:53,  2.16s/it]\u001b[A\n",
      "diffusion loop:   0%|                                                                        | 0/256 [00:00<?, ?it/s]\u001b[A/tmp/ipykernel_1318444/624903221.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  condition_R = torch.tensor(condition_R)\n",
      "/tmp/ipykernel_1318444/624903221.py:83: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  condition_T = torch.tensor(condition_T)\n",
      "\n",
      "view loop:   1%|▊                                                                    | 3/249 [00:06<08:44,  2.13s/it]\u001b[A\n",
      "diffusion loop:   0%|                                                                        | 0/256 [00:00<?, ?it/s]\u001b[A\n",
      "view loop:   1%|▊                                                                    | 3/249 [00:08<11:13,  2.74s/it]\u001b[A\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m R \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(R)\n\u001b[1;32m     15\u001b[0m T \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(T)\n\u001b[0;32m---> 17\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecord\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrecord\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_R\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_T\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mK\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_K\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m record\u001b[38;5;241m.\u001b[39mappend([img, R, T])\n\u001b[1;32m     22\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msampling/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/jcproject/miniconda3/envs/pytorch/lib/python3.10/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36msample\u001b[0;34m(model, record, target_R, target_T, K, w, timesteps)\u001b[0m\n\u001b[1;32m     86\u001b[0m     T \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([condition_T, target_T], \u001b[38;5;241m0\u001b[39m)[\u001b[38;5;28;01mNone\u001b[39;00m]\u001b[38;5;241m.\u001b[39mrepeat(b, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     87\u001b[0m     condition_img \u001b[38;5;241m=\u001b[39m condition_img\n\u001b[0;32m---> 88\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mp_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mz\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcondition_img\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mR\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mR\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mT\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mK\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mK\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mlogsnr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogsnr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogsnr_next\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogsnr_next\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m img\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[0;32m~/jcproject/miniconda3/envs/pytorch/lib/python3.10/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36mp_sample\u001b[0;34m(model, z, x, R, T, K, logsnr, logsnr_next, w)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39mno_grad()\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mp_sample\u001b[39m(model, z, x, R, T, K, logsnr, logsnr_next, w):\n\u001b[0;32m---> 60\u001b[0m     model_mean, model_variance \u001b[38;5;241m=\u001b[39m \u001b[43mp_mean_variance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m                                                 \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m                                                 \u001b[49m\u001b[43mz\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m                                                 \u001b[49m\u001b[43mR\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m                                                 \u001b[49m\u001b[43mT\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mK\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mK\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogsnr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogsnr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogsnr_next\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogsnr_next\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m logsnr_next\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     67\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m model_mean\n",
      "File \u001b[0;32m~/jcproject/miniconda3/envs/pytorch/lib/python3.10/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36mp_mean_variance\u001b[0;34m(model, x, z, R, T, K, logsnr, logsnr_next, w)\u001b[0m\n\u001b[1;32m     39\u001b[0m pred_noise \u001b[38;5;241m=\u001b[39m model(batch, cond_mask\u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;28;01mTrue\u001b[39;00m]\u001b[38;5;241m*\u001b[39mb))\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[1;32m     40\u001b[0m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn_like(x)\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[0;32m---> 41\u001b[0m pred_noise_unconditioned \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcond_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[1;32m     43\u001b[0m pred_noise_final \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m+\u001b[39mw) \u001b[38;5;241m*\u001b[39m pred_noise \u001b[38;5;241m-\u001b[39m w \u001b[38;5;241m*\u001b[39m pred_noise_unconditioned\n\u001b[1;32m     45\u001b[0m z \u001b[38;5;241m=\u001b[39m z\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\n",
      "File \u001b[0;32m~/jcproject/miniconda3/envs/pytorch/lib/python3.10/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/jcproject/miniconda3/envs/pytorch/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py:168\u001b[0m, in \u001b[0;36mDataParallel.forward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule(\u001b[38;5;241m*\u001b[39minputs[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    167\u001b[0m replicas \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplicate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice_ids[:\u001b[38;5;28mlen\u001b[39m(inputs)])\n\u001b[0;32m--> 168\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparallel_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgather(outputs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_device)\n",
      "File \u001b[0;32m~/jcproject/miniconda3/envs/pytorch/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py:178\u001b[0m, in \u001b[0;36mDataParallel.parallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparallel_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, replicas, inputs, kwargs):\n\u001b[0;32m--> 178\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparallel_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_ids\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/jcproject/miniconda3/envs/pytorch/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:78\u001b[0m, in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m     76\u001b[0m         thread\u001b[38;5;241m.\u001b[39mstart()\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m thread \u001b[38;5;129;01min\u001b[39;00m threads:\n\u001b[0;32m---> 78\u001b[0m         thread\u001b[38;5;241m.\u001b[39mjoin()\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     80\u001b[0m     _worker(\u001b[38;5;241m0\u001b[39m, modules[\u001b[38;5;241m0\u001b[39m], inputs[\u001b[38;5;241m0\u001b[39m], kwargs_tup[\u001b[38;5;241m0\u001b[39m], devices[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m~/jcproject/miniconda3/envs/pytorch/lib/python3.10/threading.py:1089\u001b[0m, in \u001b[0;36mThread.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1086\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot join current thread\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1088\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1089\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait_for_tstate_lock\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1090\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1091\u001b[0m     \u001b[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[1;32m   1092\u001b[0m     \u001b[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[1;32m   1093\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmax\u001b[39m(timeout, \u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[0;32m~/jcproject/miniconda3/envs/pytorch/lib/python3.10/threading.py:1109\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1106\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1109\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mlock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1110\u001b[0m         lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m   1111\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stop()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "w = torch.tensor([0, 1, 2, 3, 4, 5, 6, 7])\n",
    "b = w.shape[0]\n",
    "record = [[data_imgs[0][None].repeat(b, axis=0), \n",
    "           data_Rs[0],\n",
    "           data_Ts[0]]]\n",
    "\n",
    "os.makedirs(f'sampling/0', exist_ok=True)\n",
    "Image.fromarray(((data_imgs[0].transpose(1,2,0)+1)*127.5).astype(np.uint8)).save('sampling/0/gt.png')\n",
    "\n",
    "with torch.no_grad():\n",
    "    step = 1\n",
    "    for gt, R, T in tqdm(zip(data_imgs[1:], data_Rs[1:], data_Ts[1:]), total=len(data_imgs[1:]), desc='view loop', position=0):\n",
    "        \n",
    "        R = torch.tensor(R)\n",
    "        T = torch.tensor(T)\n",
    "\n",
    "        img = sample(model, record=record, target_R=R, target_T=T, K=data_K, w=w)\n",
    "        \n",
    "        record.append([img, R, T])\n",
    "        \n",
    "        \n",
    "        os.makedirs(f'sampling/{step}', exist_ok=True)\n",
    "        Image.fromarray(((gt.transpose(1,2,0)+1)*127.5).astype(np.uint8)).save(f'sampling/{step}/gt.png')\n",
    "        for i in w:\n",
    "            Image.fromarray(((img[i].transpose(1,2,0)+1)*127.5).astype(np.uint8)).save(f'sampling/{step}/{i}.png')\n",
    "        \n",
    "        step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98ffde23-10be-4873-b594-2d42fc9f420a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 64, 64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c67a2cc-2250-4588-bdb4-d99ea7cc5caf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
